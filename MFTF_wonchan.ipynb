{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bz = pd.read_csv('yelp_dataset/restaurant.csv',index_col='Unnamed: 0')\n",
    "rv = pd.read_csv('yelp_dataset/reviews_filtered.csv',index_col='Unnamed: 0')\n",
    "us = pd.read_csv('yelp_dataset/user_filtered.csv',index_col='Unnamed: 0')\n",
    "\n",
    "# bz --> rv --> us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bz1 = bz.sample(frac=0.1)\n",
    "# rv1 = bz1[['business_id']].merge(rv, how='left',on='business_id')\n",
    "# us1 = rv1[['user_id']].merge(rv1, how='left',on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rv.groupby(['business_id','user_id']).agg({'stars':'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>---1lKK3aKOuomHnwAkAow</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>-11nMat3F0DgsxT30hn8zA</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>-3fMaL_ck0wzEsTZyz-mqA</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>-47EprTYhe9IbAvplGIcpA</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>-7cPERHtAupd1Xq53nmhXg</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                 user_id  stars\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  ---1lKK3aKOuomHnwAkAow    4.0\n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  -11nMat3F0DgsxT30hn8zA    5.0\n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  -3fMaL_ck0wzEsTZyz-mqA    5.0\n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  -47EprTYhe9IbAvplGIcpA    5.0\n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  -7cPERHtAupd1Xq53nmhXg    5.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MF Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.7\n",
    "df_train = df[msk]\n",
    "user_ind = [x-1 for x in df_train['user_id'].index]\n",
    "item_ind = [x-1 for x in df_train['business_id'].index]\n",
    "stars = df_train['stars'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['business_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "feature_len = 10\n",
    "U = tf.Variable(initial_value=tf.truncated_normal([373483,feature_len]), name='users')\n",
    "P = tf.Variable(initial_value=tf.truncated_normal([feature_len,8848]), name='items')\n",
    "result = tf.matmul(U, P)\n",
    "result_flatten = tf.reshape(result, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = tf.gather(result_flatten, user_ind * tf.shape(result)[1] + \n",
    "              item_ind, name='extracting_user_stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cost function\n",
    "diff_op = tf.subtract(R, stars, name='training_diff')\n",
    "diff_op_squared = tf.abs(diff_op, name=\"squared_difference\")\n",
    "base_cost = tf.reduce_sum(diff_op_squared, name=\"sum_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularization\n",
    "lda = tf.constant(.001, name='lambda')\n",
    "norm_sums = tf.add(tf.reduce_sum(tf.abs(U, name='user_abs'), name='user_norm'), \n",
    "   tf.reduce_sum(tf.abs(P, name='item_abs'), name='item_norm'))\n",
    "regularizer = tf.multiply(norm_sums, lda, 'regularizer')\n",
    "\n",
    "cost = tf.add(base_cost, regularizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "lr = tf.constant(.001, name='learning_rate')\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(lr, global_step, 10000, 0.96, staircase=True)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_step = optimizer.minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution\n",
    "sess = tf.Session()\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "for i in xrange(500):\n",
    "    sess.run(training_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "u, p, r = df[['user', 'item', 'rate']].values[0]\n",
    "rhat = tf.gather(tf.gather(result, u-1), p-1)\n",
    "print \"rating for user \" + str(u) + \" for item \" + str(p) + \n",
    "      \" is \" + str(r) + \" and our prediction is: \" + str(sess.run(rhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "df_test = df[~msk]\n",
    "user_indecies_test = [x-1 for x in df_test.user.values]\n",
    "item_indecies_test = [x-1 for x in df_test.item.values]\n",
    "rates_test = df_test.rate.values\n",
    "\n",
    "# accuracy\n",
    "R_test = tf.gather(result_flatten, user_indecies_test * tf.shape(result)[1] + item_indecies_test, name='extracting_user_rate_test')\n",
    "diff_op_test = tf.sub(R_test, rates_test, name='test_diff')\n",
    "diff_op_squared_test = tf.abs(diff_op, name=\"squared_difference_test\")\n",
    "\n",
    "cost_test = tf.div(tf.reduce_sum(tf.square(diff_op_squared_test, name=\"squared_difference_test\"), name=\"sum_squared_error_test\"), df_test.shape[0] * 2, name=\"average_error\")\n",
    "print sess.run(cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CF Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise import similarities\n",
    "from surprise import KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bz1 = bz.sample(frac=0.1)\n",
    "# rv1 = bz1[['business_id']].merge(rv, how='left',on='business_id')\n",
    "# us1 = rv1[['user_id']].merge(rv1, how='left',on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader, the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['user_id', 'business_id', 'stars']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(NormalPredictor(), data, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into test and training\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(algo, data, measures=['rmse', 'mae'], cv=5,\n",
    "               return_train_measures=False, n_jobs=1,\n",
    "               pre_dispatch='2*n_jobs', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name': 'cosine'}\n",
    "algo2 = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "algo2.fit(trainset)\n",
    "similarities = algo2.test(testset)\n",
    "\n",
    "accuracy.rmse(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(algo2, data, measures=['rmse', 'mae'], cv=2,\n",
    "               return_train_measures=False, n_jobs=1,\n",
    "               pre_dispatch='2*n_jobs', verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
